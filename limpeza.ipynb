{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza e pré-processamento de dados com o NumPy\n",
    "\n",
    "Durante o nosso projeto, iremos utilizar exclusivamente o NumPy para realizar a limpeza e o pré-processamento dos dados. O nosso conjunto de dados representa milhares de empréstimos feitos por meio da plataforma Lending Club, que é uma plataforma que permite que indivíduos emprestem para outros indivíduos.\n",
    "\n",
    "## O que é o NumPy?\n",
    "\n",
    "Primeiramente, precisamos entender o que é o NumPy e por que o utilizaremos exclusivamente para a limpeza e o tratamento de nossos dados. O NumPy é uma das bibliotecas fundamentais para a computação científica em Python. Ele oferece suporte para arrays multidimensionais (ou seja, arrays com mais de uma dimensão) e funções matemáticas de alto desempenho para a manipulação desses arrays. O NumPy é amplamente utilizado em áreas como ciência de dados, aprendizado de máquina, processamento de sinais, matemática, física e muitos outros campos. Dado que ela é otimizada e possui funções e módulos preparados para computação científica, tende a ser mais rápida do que se utilizássemos apenas o Python puro.\n",
    "\n",
    "Visão dos dados:\n",
    "![visao inicial](imagens/01.png)\n",
    "\n",
    "\n",
    "_Ueslei Pontarolo_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Durante esse projeto iremos útilizar somente o NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorar os avisos de warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset\n",
    "\n",
    "Para importar os conjuntos de dados iremos utilizar a função _np.genfromtxt_ do NumPy que carrega os dados de um arquivo de texto e transforma em uma matriz NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando os dados\n",
    "dados = np.genfromtxt(\"dados/dataset1.csv\",\n",
    "                    delimiter = ';',\n",
    "                    skip_header = 1,\n",
    "                    autostrip = True,\n",
    "                    encoding = 'cp1252'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos verificar o tamanho do shape dos nosso dados\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8010226e+07,           nan, 3.5000000e+04, ...,           nan,\n",
       "                  nan, 9.4529600e+03],\n",
       "       [5.7693261e+07,           nan, 3.0000000e+04, ...,           nan,\n",
       "                  nan, 4.6797000e+03],\n",
       "       [5.9432726e+07,           nan, 1.5000000e+04, ...,           nan,\n",
       "                  nan, 1.9698300e+03],\n",
       "       ...,\n",
       "       [5.0415990e+07,           nan, 1.0000000e+04, ...,           nan,\n",
       "                  nan, 2.1856400e+03],\n",
       "       [4.6154151e+07,           nan,           nan, ...,           nan,\n",
       "                  nan, 3.1994000e+03],\n",
       "       [6.6055249e+07,           nan, 1.0000000e+04, ...,           nan,\n",
       "                  nan, 3.0190000e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vizualizar as entradas\n",
    "dados.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao observarmos os registros dos dados, podemos ver que temos diversos *NaN*, que significa \"Not-a-Number\" em inglês. Isso nos diz que o Python não conseguiu interpretar os dados corretamente durante a carga dos dados. Vamos resolver isso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo os problemas ao carregar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiramente vamos verificar quantos valores ausentes foram carregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para verificar os valores ausentes vamos utilizar a função isnan\n",
    "np.isnan(dados).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que temos um total de 88.005 registros como NaN. Para resolver os valores ausentes, precisamos separar nossas variáveis em dois arrays, sendo um para as variáveis *numéricas* e o outro para as variáveis do tipo *string*.\n",
    "\n",
    "Para resolver esse problema, vamos usar um pequeno truque de programação para fazer a separação. Esse truque consiste em utilizar um número arbitrário e colocá-lo na carga de dados e calcular a média dos valores NaN. Depois, iremos tratá-lo como um valor ausente.\n",
    "\n",
    "Para criar esse número arbitrário iremos utilizar a função _nanmax_ para retornar o maior valor + 1 ignorando os valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68616520.0\n"
     ]
    }
   ],
   "source": [
    "#Usaremos esse valor como o número arbitrário para preencher os valores ausente no momento da carga de dados\n",
    "num_abt = np.nanmax(dados) + 1\n",
    "print(num_abt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos calcular a média ignorando os valores _NaN_ e com isso iremos conseguir separar as variáveis numéricas de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.40158092e+07            nan 1.52734632e+04            nan\n",
      " 1.53110421e+04            nan 1.66172948e+01 4.40922179e+02\n",
      "            nan            nan            nan            nan\n",
      "            nan 3.14385094e+03]\n"
     ]
    }
   ],
   "source": [
    "#Calcular a média\n",
    "media_ign = np.nanmean(dados, axis = 0)\n",
    "print(media_ign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos verificar as colunas do tipo string com valores ausentes, e para isso, iremos usar a função _argwhere_, que retorna os índices onde uma determinada condição é verdadeira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Colunas do tipo strings\n",
    "\n",
    "columns_strings = np.argwhere(np.isnan(media_ign)).squeeze()\n",
    "columns_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos as colunas de strings, vamos aplicar a mesma essência para encontrar as colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Colunas do tipo númericas\n",
    "columns_num = np.argwhere(np.isnan(media_ign) == False).squeeze()\n",
    "columns_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os índices correspondentes as colunas númericas e de strings podemos importar novamente o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as colunas do tipo strings\n",
    "\n",
    "arr_strings = np.genfromtxt('dados/dataset1.csv',\n",
    "                            delimiter = ';',\n",
    "                            skip_header = 1,\n",
    "                            autostrip = True,\n",
    "                            usecols = columns_strings,\n",
    "                            dtype = str,\n",
    "                            encoding = 'cp1252'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226',\n",
       "        'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "        'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726',\n",
       "        'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "        'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151',\n",
       "        'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249',\n",
       "        'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar se foi carregada corretamente\n",
    "arr_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você se lembra que criamos um valor arbitrário como um truque para resolver os NaN? Pois bem, iremos utilizá-lo agora, onde iremos colocar no argumento filling_values que, caso tenha um valor faltante, esse argumento irá preencher com o nosso número arbitrário que definimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as colunas do tipo númerico\n",
    "arr_numeric = np.genfromtxt('dados/dataset1.csv',\n",
    "                            delimiter = ';',\n",
    "                            autostrip = True,\n",
    "                            skip_header = 1,\n",
    "                            usecols = columns_num,\n",
    "                            filling_values = num_abt,\n",
    "                            encoding = 'cp1252'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8010226e+07, 3.5000000e+04, 3.5000000e+04, 1.3330000e+01,\n",
       "        1.1848600e+03, 9.4529600e+03],\n",
       "       [5.7693261e+07, 3.0000000e+04, 3.0000000e+04, 6.8616520e+07,\n",
       "        9.3857000e+02, 4.6797000e+03],\n",
       "       [5.9432726e+07, 1.5000000e+04, 1.5000000e+04, 6.8616520e+07,\n",
       "        4.9486000e+02, 1.9698300e+03],\n",
       "       ...,\n",
       "       [5.0415990e+07, 1.0000000e+04, 1.0000000e+04, 6.8616520e+07,\n",
       "        6.8616520e+07, 2.1856400e+03],\n",
       "       [4.6154151e+07, 6.8616520e+07, 1.0000000e+04, 1.6550000e+01,\n",
       "        3.5430000e+02, 3.1994000e+03],\n",
       "       [6.6055249e+07, 1.0000000e+04, 1.0000000e+04, 6.8616520e+07,\n",
       "        3.0997000e+02, 3.0190000e+02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar nosso array númerico\n",
    "arr_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, nosso processo de carga não gerou nenhum NaN, porque os separamos de maneira apropriada. Também não carregamos o cabeçalho nos arrays de strings e nem nos arrays numéricos, pois ele iria influenciar na hora da separação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term',\n",
       "       'int_rate', 'installment', 'grade', 'sub_grade',\n",
       "       'verification_status', 'url', 'addr_state', 'total_pymnt'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pegando os nomes das colunas\n",
    "arr_name_columns = np.genfromtxt('dados/dataset1.csv',\n",
    "                                delimiter = ';',\n",
    "                                autostrip = True,\n",
    "                                skip_footer = dados.shape[0],\n",
    "                                dtype = str,\n",
    "                                encoding = 'cp1252'\n",
    "\n",
    ")\n",
    "\n",
    "arr_name_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os nomes dos cabeçalhos, iremos separá-los entre as colunas numéricas e as colunas de strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade',\n",
       "        'verification_status', 'url', 'addr_state'], dtype='<U19'),\n",
       " array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment',\n",
       "        'total_pymnt'], dtype='<U19'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fazendo a separação\n",
    "header_strings, header_numeric = arr_name_columns[columns_strings], arr_name_columns[columns_num]\n",
    "\n",
    "#Vamos ver como ficou cada header\n",
    "header_strings, header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando as colunas do tipo string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já fizemos o carregamento inicial dos dados, assim como a separação entre strings e variáveis, vamos começar o tratamento das colunas de strings.\n",
    "\n",
    "O primeiro passo que iremos fazer é alterar o nome da coluna \"issue_d\" para facilitar na identificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade',\n",
       "       'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade',\n",
       "       'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alterar de issue_d para issue_date\n",
    "header_strings[0] = 'issue_date'\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento da variável issue_date com o Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15',\n",
       "       'Jun-15', 'Mar-15', 'May-15', 'Nov-15', 'Oct-15', 'Sep-15'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar os valores únicos da variável\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando esses dados foram gerados, ninguém estava pensando em análise de datas, portanto, acharam necessário colocar o dia em que esses dados foram gerados, que, no caso, como podemos observar, foi no dia 15 de cada mês.\n",
    "\n",
    "Vamos remover esse sufixo '-15' aplicando o método strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May',\n",
       "       'Nov', 'Oct', 'Sep'], dtype='<U69')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removendo o sufixo -15\n",
    "arr_strings[:,0] = np.chararray.strip(arr_strings[:,0], \"-15\")\n",
    "\n",
    "#vamos verificar como ficou\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos somente os meses, vamos aplicar o Label Encoding para transformar as strings em valores numéricos sem perder suas informações. Para isso, iremos criar um loop que irá percorrer cada elemento do array e verificar se ele corresponde ao array de meses (que iremos criar a seguir). Caso haja correspondência, iremos atribuir o valor numérico correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o array com os meses, incluindo um elemento vazio para o que estiver em branco\n",
    "meses = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
