{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza e pré-processamento de dados com o NumPy\n",
    "\n",
    "Durante o nosso projeto, iremos utilizar exclusivamente o NumPy para realizar a limpeza e o pré-processamento dos dados. O nosso conjunto de dados representa milhares de empréstimos feitos por meio da plataforma Lending Club, que é uma plataforma que permite que indivíduos emprestem para outros indivíduos.\n",
    "\n",
    "## O que é o NumPy?\n",
    "\n",
    "Primeiramente, precisamos entender o que é o NumPy e por que o utilizaremos exclusivamente para a limpeza e o tratamento de nossos dados. O NumPy é uma das bibliotecas fundamentais para a computação científica em Python. Ele oferece suporte para arrays multidimensionais (ou seja, arrays com mais de uma dimensão) e funções matemáticas de alto desempenho para a manipulação desses arrays. O NumPy é amplamente utilizado em áreas como ciência de dados, aprendizado de máquina, processamento de sinais, matemática, física e muitos outros campos. Dado que ela é otimizada e possui funções e módulos preparados para computação científica, tende a ser mais rápida do que se utilizássemos apenas o Python puro.\n",
    "\n",
    "Visão dos dados:\n",
    "![visao inicial](imagens/01.png)\n",
    "\n",
    "\n",
    "_Ueslei Pontarolo_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Durante esse projeto iremos útilizar somente o NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorar os avisos de warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset\n",
    "\n",
    "Para importar os conjuntos de dados iremos utilizar a função _np.genfromtxt_ do NumPy que carrega os dados de um arquivo de texto e transforma em uma matriz NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando os dados\n",
    "dados = np.genfromtxt(\"dados/dataset1.csv\",\n",
    "                    delimiter = ';',\n",
    "                    skip_header = 1,\n",
    "                    autostrip = True,\n",
    "                    encoding = 'cp1252'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos verificar o tamanho do shape dos nosso dados\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8010226e+07,           nan, 3.5000000e+04, ...,           nan,\n",
       "                  nan, 9.4529600e+03],\n",
       "       [5.7693261e+07,           nan, 3.0000000e+04, ...,           nan,\n",
       "                  nan, 4.6797000e+03],\n",
       "       [5.9432726e+07,           nan, 1.5000000e+04, ...,           nan,\n",
       "                  nan, 1.9698300e+03],\n",
       "       ...,\n",
       "       [5.0415990e+07,           nan, 1.0000000e+04, ...,           nan,\n",
       "                  nan, 2.1856400e+03],\n",
       "       [4.6154151e+07,           nan,           nan, ...,           nan,\n",
       "                  nan, 3.1994000e+03],\n",
       "       [6.6055249e+07,           nan, 1.0000000e+04, ...,           nan,\n",
       "                  nan, 3.0190000e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vizualizar as entradas\n",
    "dados.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao observarmos os registros dos dados, podemos ver que temos diversos *NaN*, que significa \"Not-a-Number\" em inglês. Isso nos diz que o Python não conseguiu interpretar os dados corretamente durante a carga dos dados. Vamos resolver isso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo os problemas ao carregar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiramente vamos verificar quantos valores ausentes foram carregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para verificar os valores ausentes vamos utilizar a função isnan\n",
    "np.isnan(dados).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que temos um total de 88.005 registros como NaN. Para resolver os valores ausentes, precisamos separar nossas variáveis em dois arrays, sendo um para as variáveis *numéricas* e o outro para as variáveis do tipo *string*.\n",
    "\n",
    "Para resolver esse problema, vamos usar um pequeno truque de programação para fazer a separação. Esse truque consiste em utilizar um número arbitrário e colocá-lo na carga de dados e calcular a média dos valores NaN. Depois, iremos tratá-lo como um valor ausente.\n",
    "\n",
    "Para criar esse número arbitrário iremos utilizar a função _nanmax_ para retornar o maior valor + 1 ignorando os valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68616520.0\n"
     ]
    }
   ],
   "source": [
    "#Usaremos esse valor como o número arbitrário para preencher os valores ausente no momento da carga de dados\n",
    "num_abt = np.nanmax(dados) + 1\n",
    "print(num_abt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos calcular a média ignorando os valores _NaN_ e com isso iremos conseguir separar as variáveis numéricas de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.40158092e+07            nan 1.52734632e+04            nan\n",
      " 1.53110421e+04            nan 1.66172948e+01 4.40922179e+02\n",
      "            nan            nan            nan            nan\n",
      "            nan 3.14385094e+03]\n"
     ]
    }
   ],
   "source": [
    "#Calcular a média\n",
    "media_ign = np.nanmean(dados, axis = 0)\n",
    "print(media_ign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos verificar as colunas do tipo string com valores ausentes, e para isso, iremos usar a função _argwhere_, que retorna os índices onde uma determinada condição é verdadeira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Colunas do tipo strings\n",
    "\n",
    "columns_strings = np.argwhere(np.isnan(media_ign)).squeeze()\n",
    "columns_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos as colunas de strings, vamos aplicar a mesma essência para encontrar as colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Colunas do tipo númericas\n",
    "columns_num = np.argwhere(np.isnan(media_ign) == False).squeeze()\n",
    "columns_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os índices correspondentes as colunas númericas e de strings podemos importar novamente o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as colunas do tipo strings\n",
    "\n",
    "arr_strings = np.genfromtxt('dados/dataset1.csv',\n",
    "                            delimiter = ';',\n",
    "                            skip_header = 1,\n",
    "                            autostrip = True,\n",
    "                            usecols = columns_strings,\n",
    "                            dtype = str,\n",
    "                            encoding = 'cp1252'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226',\n",
       "        'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "        'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726',\n",
       "        'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "        'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151',\n",
       "        'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249',\n",
       "        'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar se foi carregada corretamente\n",
    "arr_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você se lembra que criamos um valor arbitrário como um truque para resolver os NaN? Pois bem, iremos utilizá-lo agora, onde iremos colocar no argumento filling_values que, caso tenha um valor faltante, esse argumento irá preencher com o nosso número arbitrário que definimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as colunas do tipo númerico\n",
    "arr_numeric = np.genfromtxt('dados/dataset1.csv',\n",
    "                            delimiter = ';',\n",
    "                            autostrip = True,\n",
    "                            skip_header = 1,\n",
    "                            usecols = columns_num,\n",
    "                            filling_values = num_abt,\n",
    "                            encoding = 'cp1252'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8010226e+07, 3.5000000e+04, 3.5000000e+04, 1.3330000e+01,\n",
       "        1.1848600e+03, 9.4529600e+03],\n",
       "       [5.7693261e+07, 3.0000000e+04, 3.0000000e+04, 6.8616520e+07,\n",
       "        9.3857000e+02, 4.6797000e+03],\n",
       "       [5.9432726e+07, 1.5000000e+04, 1.5000000e+04, 6.8616520e+07,\n",
       "        4.9486000e+02, 1.9698300e+03],\n",
       "       ...,\n",
       "       [5.0415990e+07, 1.0000000e+04, 1.0000000e+04, 6.8616520e+07,\n",
       "        6.8616520e+07, 2.1856400e+03],\n",
       "       [4.6154151e+07, 6.8616520e+07, 1.0000000e+04, 1.6550000e+01,\n",
       "        3.5430000e+02, 3.1994000e+03],\n",
       "       [6.6055249e+07, 1.0000000e+04, 1.0000000e+04, 6.8616520e+07,\n",
       "        3.0997000e+02, 3.0190000e+02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar nosso array númerico\n",
    "arr_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, nosso processo de carga não gerou nenhum NaN, porque os separamos de maneira apropriada. Também não carregamos o cabeçalho nos arrays de strings e nem nos arrays numéricos, pois ele iria influenciar na hora da separação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term',\n",
       "       'int_rate', 'installment', 'grade', 'sub_grade',\n",
       "       'verification_status', 'url', 'addr_state', 'total_pymnt'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pegando os nomes das colunas\n",
    "arr_name_columns = np.genfromtxt('dados/dataset1.csv',\n",
    "                                delimiter = ';',\n",
    "                                autostrip = True,\n",
    "                                skip_footer = dados.shape[0],\n",
    "                                dtype = str,\n",
    "                                encoding = 'cp1252'\n",
    "\n",
    ")\n",
    "\n",
    "arr_name_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os nomes dos cabeçalhos, iremos separá-los entre as colunas numéricas e as colunas de strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade',\n",
       "        'verification_status', 'url', 'addr_state'], dtype='<U19'),\n",
       " array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment',\n",
       "        'total_pymnt'], dtype='<U19'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fazendo a separação\n",
    "header_strings, header_numeric = arr_name_columns[columns_strings], arr_name_columns[columns_num]\n",
    "\n",
    "#Vamos ver como ficou cada header\n",
    "header_strings, header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando as colunas do tipo string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já fizemos o carregamento inicial dos dados, assim como a separação entre strings e variáveis, vamos começar o tratamento das colunas de strings.\n",
    "\n",
    "O primeiro passo que iremos fazer é alterar o nome da coluna \"issue_d\" para facilitar na identificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade',\n",
       "       'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade',\n",
       "       'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alterar de issue_d para issue_date\n",
    "header_strings[0] = 'issue_date'\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento da variável issue_date com o Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15',\n",
       "       'Jun-15', 'Mar-15', 'May-15', 'Nov-15', 'Oct-15', 'Sep-15'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar os valores únicos da variável\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando esses dados foram gerados, ninguém estava pensando em análise de datas, portanto, acharam necessário colocar o dia em que esses dados foram gerados, que, no caso, como podemos observar, foi no dia 15 de cada mês.\n",
    "\n",
    "Vamos remover esse sufixo '-15' aplicando o método strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May',\n",
       "       'Nov', 'Oct', 'Sep'], dtype='<U69')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removendo o sufixo -15\n",
    "arr_strings[:,0] = np.chararray.strip(arr_strings[:,0], \"-15\")\n",
    "\n",
    "#vamos verificar como ficou\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos somente os meses, vamos aplicar o Label Encoding para transformar as strings em valores numéricos sem perder suas informações. Para isso, iremos criar um loop que irá percorrer cada elemento do array e verificar se ele corresponde ao array de meses (que iremos criar a seguir). Caso haja correspondência, iremos atribuir o valor numérico correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o array com os meses, incluindo um elemento vazio para o que estiver em branco\n",
    "meses = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop para converter os nomes dos meses em valores númericos\n",
    "for i in range(13):\n",
    "    arr_strings[:,0] = np.where(arr_strings[:,0] == meses[i], i, arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando como ficou\n",
    "np.unique(arr_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento da coluna loan_status com a binarização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid',\n",
       "       'In Grace Period', 'Issued', 'Late (16-30 days)',\n",
       "       'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(arr_strings[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que a categoria \"loan_status\" possui 9 categorias. No entanto, para um futuro modelo de machine learning, precisamos realmente de todas essas categorias? Bem, não existe uma resposta correta para isso. O que precisamos fazer é testar e verificar como essas categorias se comportam. No entanto, para este projeto, iremos trabalhar apenas com as categorias '', 'Charged Off', 'Default' e 'Late (31-120 days)'. Se um empréstimo cair em uma dessas 4 categorias, atribuiremos o valor zero, o que significa que a pessoa está tendo problemas para pagar o empréstimo. Caso contrário, atribuiremos o valor 1, o que significa que as pessoas estão pagando os empréstimos. Esse processo é chamado de binarização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um array com os status ruim\n",
    "status_bad = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agora vamos fazer a atribuição se o valor for igual ao nosso bad status iremos atribuir o 0 senão o 1\n",
    "arr_strings[:,1] = np.where(np.isin(arr_strings[:,1], status_bad),0,1)\n",
    "\n",
    "#Vamos verificar como ficou\n",
    "np.unique(arr_strings[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento da coluna term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos verificar os valores presentes na coluna term\n",
    "np.unique(arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que as pessoas têm apenas 2 opções de pagamento, sendo elas 36 meses ou 60 meses. Também temos valores ausentes, e para corrigi-los, iremos utilizar o maior prazo possível de pagamento, que é de 60 meses. Além disso, vamos remover a palavra \"months\" das variáveis para deixá-las apenas no formato numérico e colocar essa informação no nome da coluna, para que possamos compreender o significado dos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo a palavra months\n",
    "arr_strings[:,2] = np.chararray.strip(arr_strings[:,2], ' months')\n",
    "\n",
    "#renomear o nome da coluna\n",
    "header_strings[2] = 'term_months'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69'),\n",
       " array(['36', '60'], dtype='<U69'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos substituir os valores ausentes\n",
    "arr_strings[:,2] = np.where(arr_strings[:,2] == '', '60', arr_strings[:,2])\n",
    "\n",
    "#vamos verificar como ficou\n",
    "arr_strings[:,2], np.unique(arr_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento das colunas grade e sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69'),\n",
       " array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5',\n",
       "        'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1',\n",
       "        'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2',\n",
       "        'G3', 'G4', 'G5'], dtype='<U69'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos verificar os valores unicos de ambas as colunas\n",
    "\n",
    "np.unique(arr_strings[:,3]), np.unique(arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repararmos nas duas colunas, elas representam uma espécie de nota para cada pessoa. Além disso, são bem parecidas, o que nos faz questionar se realmente é necessário ter as duas colunas, dado que em um algoritmo de machine learning estaríamos reforçando uma informação. Portanto, vamos manter a coluna \"sub_grade\", dado que ela possui uma nota mais detalhada do que a \"grade\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para ajuste da variável sub_grade\n",
    "for i in np.unique(arr_strings[:,3])[1:]:\n",
    "    arr_strings[:,4] = np.where((arr_strings[:,4] == '') & (arr_strings[:,3] == i), i + '5', arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5',\n",
       "        'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1',\n",
       "        'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2',\n",
       "        'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567,\n",
       "        586, 564, 577, 391, 267, 250, 255, 288, 235, 162, 171, 139, 160,\n",
       "         94,  52,  34,  43,  24,  19,  10,   3,   7,   5], dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos verificar as categorias da sub_grade e suas respectivas contagem\n",
    "\n",
    "np.unique(arr_strings[:,4], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos substituir os 9 valores ausentes criando uma nova categoria chamada 'H1', já que não sabemos a nota desses clientes. Também poderíamos utilizar a moda, porém vamos continuar com essa abordagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrigindo os ausentes\n",
    "arr_strings[:,4] = np.where(arr_strings[:,4] == '', 'H1', arr_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já tratamos a sub_grade não precisamos mais da coluna grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo a coluna grade\n",
    "arr_strings = np.delete(arr_strings, 3, axis=1)\n",
    "\n",
    "#Removendo também do array de nomes\n",
    "header_strings = np.delete(header_strings, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos converter a variável \"sub_grade\" para sua representação numérica sem perder nenhuma informação e para isso vamos criar um dicionario e extrair os valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar lista de chaves\n",
    "keys = list(np.unique(arr_strings[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar a lista de valores\n",
    "values = list(range(1, np.unique(arr_strings[:,3]).shape[0] + 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H1': 36}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos criar o dicionario\n",
    "dict_sub_grade = dict(zip(keys, values))\n",
    "dict_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substituir a string com a sua representação númerica\n",
    "for i in np.unique(arr_strings[:,3]):\n",
    "    arr_strings[:,3] = np.where(arr_strings[:,3] == i, dict_sub_grade[i], arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19',\n",
       "       '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
       "       '3', '30', '31', '32', '33', '34', '35', '36', '4', '5', '6', '7',\n",
       "       '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos verificar comoficou\n",
    "np.unique(arr_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
